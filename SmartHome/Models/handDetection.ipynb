{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "#from tensorflow.keras.models import load_model\n",
    "#queue to find the right gesture\n",
    "from collections import deque\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IdentifyGesture(prediction):\n",
    "    #print(prediction)\n",
    "    if prediction == 0:\n",
    "        return \"Peace sign\"\n",
    "    elif prediction == 1:\n",
    "        return \"Tilted finger gun with thumb up\"\n",
    "    elif prediction == 2:\n",
    "        return \"Upward fist\"\n",
    "    elif prediction == 3:\n",
    "        return \"Three fingers up\"\n",
    "    elif prediction == 4:\n",
    "        return \"Crossed fingers\"\n",
    "    elif prediction == 5:\n",
    "        return \"O with fingers\"\n",
    "    elif prediction == 6:\n",
    "        return \"Upward fist with fingers forward\"\n",
    "    elif prediction == 7:\n",
    "        return \"One finger pointed up\"\n",
    "    elif prediction == 8:\n",
    "        return \"Two fingers pointing in a direction\"\n",
    "    else:\n",
    "        print(prediction)\n",
    "        return \"none\"\n",
    "\n",
    "def calculate_angle(p1, p2, p3):\n",
    "    \"\"\"Calculate the angle between three points.\"\"\"\n",
    "    a = math.sqrt((p2.x - p3.x)**2 + (p2.y - p3.y)**2)\n",
    "    b = math.sqrt((p1.x - p3.x)**2 + (p1.y - p3.y)**2)\n",
    "    c = math.sqrt((p1.x - p2.x)**2 + (p1.y - p2.y)**2)\n",
    "    angle = math.acos((a**2 + c**2 - b**2) / (2 * a * c))\n",
    "    return math.degrees(angle)\n",
    "\n",
    "    # In your existing thumbClassifier, incorporate angle calculations where needed.\n",
    "    # For example, to check if the thumb is extended in a thumbs-up gesture:\n",
    "    \n",
    "class hand:\n",
    "    def __init__(self,hand):\n",
    "        self.wrist = hand.landmark[0]\n",
    "        self.thumb = finger(hand.landmark[1:5],self.wrist)\n",
    "        self.indexFinger = finger(hand.landmark[5:9],self.wrist)\n",
    "        self.middleFinger = finger(hand.landmark[9:13],self.wrist)\n",
    "        self.ringFinger = finger(hand.landmark[13:17],self.wrist)\n",
    "        self.pinky = finger(hand.landmark[17:21],self.wrist)\n",
    "        self.fingers = [self.thumb,self.indexFinger,self.middleFinger,self.ringFinger,self.pinky]\n",
    "        self.fingersUp, self.fingersDown,self.fingersFlat = self.getFingerDirections()\n",
    "        self.gesture = self.getGesture()\n",
    "    def getFingerDirections(self):\n",
    "        up,down,flat=0,0,0\n",
    "        for finger in self.fingers:\n",
    "            if finger.direction == 'up':\n",
    "                up+=1\n",
    "            elif finger.direction =='down':\n",
    "                down+=1\n",
    "            else:\n",
    "                flat+=1\n",
    "        return up,down,flat\n",
    "    \n",
    "    def getGesture(self):\n",
    "        # Refine gesture detection using counts\n",
    "        if self.fingersUp == 4 and self.thumb.direction == 'up':\n",
    "            return 'five fingers up'\n",
    "        elif self.fingersUp == 4:\n",
    "            return 'four fingers up'\n",
    "        elif self.fingersUp == 3:\n",
    "            return 'three fingers up'\n",
    "        elif self.fingersUp == 2:\n",
    "            return 'two fingers up'\n",
    "        elif self.indexFinger.direction == 'up' and self.fingersUp == 1:\n",
    "            return 'one finger up - index'\n",
    "        elif self.thumb.direction == 'up':\n",
    "            return 'thumbs up'\n",
    "        elif self.thumb.direction == 'down':\n",
    "            return 'thumbs down'\n",
    "        elif self.thumb.direction == 'flat':\n",
    "            return 'thumb flat'\n",
    "        else:\n",
    "            return 'unknown gesture'\n",
    "            \n",
    "\n",
    "class finger:\n",
    "    def __init__(self, points, wrist):\n",
    "        self.wrist = wrist\n",
    "        self.points = points\n",
    "        self.direction=self.getDirection()\n",
    "        self.angle = self.calculate_angle(points[-1], wrist, points[0])\n",
    "        #print(self.angle)\n",
    "    def getDirection(self):\n",
    "        upPoints=0\n",
    "        downPoints=0\n",
    "        for i in range(len(self.points)-1):\n",
    "            if self.points[i].y > self.points[i+1].y:\n",
    "                upPoints+=1\n",
    "            else:\n",
    "                downPoints+=1\n",
    "        if abs(self.points[2].y - self.wrist.y)<0.2:\n",
    "            return 'flat'\n",
    "        else:\n",
    "            return 'up' if upPoints>downPoints else 'down'\n",
    "    \n",
    "    def calculate_angle(self,p1, p2, p3):\n",
    "        # Calculate the sides of the triangle\n",
    "        a = math.sqrt((p2.x - p3.x) ** 2 + (p2.y - p3.y) ** 2)\n",
    "        b = math.sqrt((p1.x - p3.x) ** 2 + (p1.y - p3.y) ** 2)\n",
    "        c = math.sqrt((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2)\n",
    "\n",
    "        # Calculate the angle at p1 using the cosine rule\n",
    "        angle = math.acos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))\n",
    "        return math.degrees(angle)\n",
    "    \n",
    "            \n",
    "def thumbClassifier(results):\n",
    "    res=results.multi_hand_landmarks[0].landmark\n",
    "    GestureObject = hand(results.multi_hand_landmarks[0])\n",
    "    \n",
    "    # print('Thumb angle: ', thumb.angle)\n",
    "    # print('Ring Finger angle: ', ringFinger.angle)\n",
    "    # print('Middle Finger angle: ', middleFinger.angle)\n",
    "    # print('Index Finger angle: ', indexFinger.angle)\n",
    "    # print('Pinky Finger angle: ', pinkyFinger.angle)\n",
    "    # print(wrist.x, wrist.y, wrist.z)\n",
    "\n",
    "    return GestureObject.gesture\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createSquare(results, img):\n",
    "    h, w, c = img.shape\n",
    "    min_x, min_y = w, h\n",
    "    max_x, max_y = 0, 0\n",
    "    #print(results.multi_hand_landmarks)\n",
    "    for lm in results.multi_hand_landmarks[0].landmark:\n",
    "        \n",
    "        # Convert the normalized position to pixel coordinates\n",
    "        cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "\n",
    "        # Update min and max coordinates based on current landmark\n",
    "        min_x, min_y = min(min_x, cx), min(min_y, cy)\n",
    "        max_x, max_y = max(max_x, cx), max(max_y, cy)\n",
    "    \n",
    "    center_x, center_y = (min_x + max_x) // 2, (min_y + max_y) // 2\n",
    "\n",
    "    # Determine the side length of the square by finding the maximum dimension\n",
    "    side_length = max(max_x - min_x, max_y - min_y)\n",
    "\n",
    "    # Ensure the square doesn't go outside the image boundaries\n",
    "    square_half_length = side_length // 2\n",
    "    new_min_x = max(center_x - square_half_length, 0)\n",
    "    new_max_x = min(center_x + square_half_length, w)\n",
    "    new_min_y = max(center_y - square_half_length, 0)\n",
    "    new_max_y = min(center_y + square_half_length, h)\n",
    "\n",
    "    # Adjust the square dimensions if they go beyond the image's height or width\n",
    "    if new_min_x < 0:\n",
    "        new_max_x -= new_min_x  # Adjust the max_x accordingly\n",
    "        new_min_x = 0\n",
    "    if new_min_y < 0:\n",
    "        new_max_y -= new_min_y  # Adjust the max_y accordingly\n",
    "        new_min_y = 0\n",
    "    if new_max_x > w:\n",
    "        new_min_x -= (new_max_x - w)  # Adjust the min_x accordingly\n",
    "        new_max_x = w\n",
    "    if new_max_y > h:\n",
    "        new_min_y -= (new_max_y - h)  # Adjust the min_y accordingly\n",
    "        new_max_y = h\n",
    "    return new_min_x, new_min_y, new_max_x, new_max_y\n",
    "\n",
    "def preprocessHandRegion(handRegion):\n",
    "    #resize the image to the same resolution used in the dataset\n",
    "    resized_hand = cv2.resize(handRegion, (224,224))\n",
    "    normalized_hand = resized_hand / 255.0\n",
    "    \n",
    "    reshaped_hand = np.reshape(normalized_hand, (224,224, 3))\n",
    "    batch_hand = np.expand_dims(reshaped_hand, axis=0)\n",
    "    return batch_hand\n",
    "\n",
    "def getHandFromImage(img,hands):\n",
    "    results = hands.process(img)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        minX, minY, maxX, maxY = createSquare(results, img)\n",
    "        if minX < maxX and minY < maxY:\n",
    "            cv2.rectangle(img, (minX, minY), (maxX, maxY), (255, 255, 25), 2)\n",
    "            handRegion = img[minY:maxY, minX:maxX]\n",
    "        else:\n",
    "            print(\"error in getHandFromImage\")\n",
    "            return None, img\n",
    "        return handRegion, img\n",
    "\n",
    "def detectHand(hands, cap, cTime, pTime, ASLModel, colors):\n",
    "    \n",
    "    gestureName=\"\"\n",
    "    success, img = cap.read()\n",
    "    cv2.putText(img, \"looking for ASL gestures\", (int(img.shape[1]/2),20), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 2)\n",
    "    if not success:\n",
    "        print(\"empty camera frame!!!!!\")\n",
    "        \n",
    "    results = hands.process(img)\n",
    "    if results.multi_hand_landmarks:\n",
    "        #get the dimensions for the cropped image\n",
    "        minX,minY,maxX,maxY=createSquare(results,img)\n",
    "        # Draw the square bounding box\n",
    "        cv2.rectangle(img, (minX, minY), (maxX, maxY), (colors, colors, colors), 2)\n",
    "        if minX < maxX and minY < maxY:\n",
    "            handRegion = img[minY:maxY, minX:maxX]\n",
    "            #Preprocess the hand region for the ASL model\n",
    "            preprocessedHand = preprocessHandRegion(handRegion) \n",
    "            #Predict the ASL gesture given by user\n",
    "            #asl_prediction = ASLModel.predict(preprocessedHand) \n",
    "            asl_prediction = 1\n",
    "            #turning the gesture from clas number to real name and adding to video feed\n",
    "            #gestureName = \"Detected Gesture: \" + IdentifyGesture(np.argmax(asl_prediction)) \n",
    "            gestureName = thumbClassifier(results)\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime\n",
    "    \n",
    "    #adding all the text before displaying the image\n",
    "    cv2.putText(img, gestureName, (10, 130), cv2.FONT_HERSHEY_PLAIN, 2, (colors, colors, colors), 2)\n",
    "    cv2.putText(img,str(int(fps)), (10,70), cv2.FONT_HERSHEY_PLAIN, 3, (colors,50,colors), 3)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)\n",
    "    return pTime, cTime, gestureName\n",
    "\n",
    "def InstructionCommand(hands, cap, cTime, pTime,firstDetected):\n",
    "    result = \"\"\n",
    "    success, img = cap.read()\n",
    "    cv2.putText(img, f'''Thumbs for  {firstDetected}''', (int(img.shape[1]/3),20), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 2)\n",
    "    if not success:\n",
    "        print(\"empty camera frame!!!!!\")\n",
    "    \n",
    "    results = hands.process(img)\n",
    "    if results.multi_hand_landmarks:\n",
    "        #get the dimensions for the cropped image\n",
    "        minX,minY,maxX,maxY=createSquare(results,img)\n",
    "        # Draw the square bounding box\n",
    "        cv2.rectangle(img, (minX, minY), (maxX, maxY), (0, 0, 0), 2)\n",
    "        if minX < maxX and minY < maxY:\n",
    "            result = thumbClassifier(results)\n",
    "        \n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime\n",
    "        \n",
    "    cv2.putText(img,result, (10,130), cv2.FONT_HERSHEY_PLAIN, 3, (100,50,100), 3)\n",
    "    cv2.putText(img,str(int(fps))+' FPS', (10,70), cv2.FONT_HERSHEY_PLAIN, 3, (100,50,100), 3)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)\n",
    "    return pTime, cTime, result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "pTime = 0\n",
    "cTime = 0\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(static_image_mode=False,\n",
    "                      max_num_hands=1,\n",
    "                      min_detection_confidence=0.5,\n",
    "                      min_tracking_confidence=0.5)\n",
    "\n",
    "\n",
    "firstDetected,secondDetected=None, None\n",
    "#ASLModel=load_model('v5model')\n",
    "ASLModel = \"\"\n",
    "\n",
    "\n",
    "queue=deque(maxlen=10)\n",
    "queueTwo=deque(maxlen=30)\n",
    "while True:\n",
    "    print('start')\n",
    "    pTime,cTime, detected = detectHand(hands,cap, cTime, pTime, ASLModel, 155)\n",
    "    if detected!='': queue.append(detected)\n",
    "    if len(queue)==10 and len(set(queue))==1:\n",
    "        queue.clear()\n",
    "        firstDetected=detected\n",
    "        #print(f'{firstDetected} is the one.')\n",
    "        break\n",
    "while True:\n",
    "    pTime, cTime, detected = InstructionCommand(hands,cap,cTime,pTime, firstDetected)\n",
    "    if detected: queueTwo.append(detected)\n",
    "    #print(detected)\n",
    "    if len(queueTwo)==30 and len(set(queueTwo))==1:\n",
    "        queue.clear()\n",
    "        secondDetected=detected\n",
    "        print(f'{firstDetected} then {secondDetected} is your first/second command, exiting now.')\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
