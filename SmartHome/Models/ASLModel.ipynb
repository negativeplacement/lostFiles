{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "# Data preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# Visualization\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Suppressing warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
    "    nunique = df.nunique()\n",
    "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
    "    nRow, nCol = df.shape\n",
    "    columnNames = list(df)\n",
    "    nGraphRow = int((nCol + nGraphPerRow - 1) / nGraphPerRow)\n",
    "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
    "    for i in range(min(nCol, nGraphShown)):\n",
    "        plt.subplot(int(nGraphRow), int(nGraphPerRow), i + 1)\n",
    "        columnDf = df.iloc[:, i]\n",
    "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
    "            valueCounts = columnDf.value_counts()\n",
    "            valueCounts.plot.bar()\n",
    "        else:\n",
    "            columnDf.hist()\n",
    "        plt.ylabel('counts')\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.title(f'{columnNames[i]} (column {i})')\n",
    "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('signlanguagemnist\\sign_mnist_train\\sign_mnist_train.csv')\n",
    "df.dataframeName = 'sign_mnist_test.csv'\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPerColumnDistribution(df, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('signlanguagemnist\\sign_mnist_train\\sign_mnist_train.csv')\n",
    "test = pd.read_csv('signlanguagemnist\\sign_mnist_test\\sign_mnist_test.csv')\n",
    "\n",
    "\n",
    "train = train[train['label'].isin( [21, 11, 0, 22, 17, 14, 4, 3,7])]\n",
    "test = test[test['label'].isin( [21, 11, 0, 22, 17, 14, 4, 3,7])]\n",
    "\n",
    "train['label'] = train['label'].map({21:0, 11:1, 0:2, 22:3, 17:4, 14:5, 4:6, 3:7, 7:8})\n",
    "test['label'] = test['label'].map({21:0, 11:1, 0:2, 22:3, 17:4, 14:5, 4:6, 3:7, 7:8})\n",
    "\n",
    "images, labels = train.iloc[:, 1:], train['label']\n",
    "testImages, testLabels = test.iloc[:, 1:], test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying one image for each class\n",
    "def displayImgForEveryClass(images, labels):\n",
    "    plt.figure(figsize=(15, 15))  # Adjust the figure size as necessary\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        # Find the first occurrence of the label\n",
    "        index = labels[labels == label].index[0]\n",
    "        \n",
    "        # Extract the corresponding image\n",
    "        img = images.loc[index].values.reshape(28, 28)\n",
    "        \n",
    "        plt.subplot(5, 5, i + 1)  # Adjust grid size based on the number of unique labels\n",
    "        plt.title(f'Label: {label}')\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# K, J A, W, R, O, E, D, H\n",
    "# Call the function to display the images\n",
    "displayImgForEveryClass(images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHands = mp.solutions.hands\n",
    "\n",
    "hands = mpHands.Hands(static_image_mode=True,\n",
    "                      max_num_hands=1,\n",
    "                      min_detection_confidence=0.5,\n",
    "                      min_tracking_confidence=0.5,\n",
    "                      model_complexity = 1)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "def draw_bounding_box_around_gesture(image):\n",
    "    \n",
    "    rows, cols = np.where(image > 0)\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    if results.multi_hand_landmarks:\n",
    "        h, w = img.shape\n",
    "        min_x, min_y = w, h\n",
    "        max_x, max_y = 0, 0\n",
    "        for id, lm in enumerate(results.multi_hand_landmarks[0].landmark):\n",
    "            # Convert the normalized position to pixel coordinates\n",
    "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "\n",
    "            # Update min and max coordinates based on current landmark\n",
    "            min_x, min_y = min(min_x, cx), min(min_y, cy)\n",
    "            max_x, max_y = max(max_x, cx), max(max_y, cy)\n",
    "        \n",
    "        center_x, center_y = (min_x + max_x) // 2, (min_y + max_y) // 2\n",
    "        width, height = 1.3*(max_x - min_x), 1.3*(max_y - min_y)\n",
    "        \n",
    "        new_min_x, new_min_y = int(center_x - width / 2), int(center_y -  height / 2)\n",
    "        new_max_x, new_max_y = int(center_x + width / 2), int(center_y +  height / 2)\n",
    "        cv2.rectangle(img, (new_min_x, new_min_y), (new_max_x, new_max_y), (255, 255, 25), 1)\n",
    "        plt.title(f'Label: {labels.iloc[index]}')\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('no hand detected')\n",
    "\n",
    "\n",
    "\n",
    "def display_image(index):   \n",
    "    \n",
    "    plt.title(f'Label: {labels[index]}')\n",
    "    plt.imshow(images.loc[index].values.reshape(28, 28), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "index = 0  # Example index\n",
    "unique_labels = np.unique(labels)\n",
    "for index in range(len(np.array(labels))):\n",
    "    # Find the first occurrence of the label\n",
    "    img = images.iloc[index].values.reshape(28, 28).astype(np.uint8)\n",
    "    \n",
    "    draw_bounding_box_around_gesture(img)\n",
    "    label = labels.iloc[index]\n",
    "    plt.title(f'Label: {labels.iloc[index]}')\n",
    "    #plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "labels = to_categorical(labels, num_classes = 9)\n",
    "testLabels = to_categorical(testLabels, num_classes = 9)\n",
    "# Train-test validation split\n",
    "trainX, testX, trainY, testY = train_test_split(images, labels, random_state = 0)\n",
    "# Reshaping data and scaling it from 0 to 1\n",
    "trainX, testX, testImages = [data.to_numpy().reshape(-1, 28, 28, 1) / 255 for data in [trainX, testX, testImages]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 15,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1\n",
    ")\n",
    "\n",
    "testDatagen = ImageDataGenerator()\n",
    "\n",
    "trainGen = datagen.flow(trainX, trainY, batch_size = 512)\n",
    "validGen = testDatagen.flow(testX, testY, batch_size = 512)\n",
    "testGen = testDatagen.flow(testImages, testLabels, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Conv2D(64, (5, 5), activation = 'relu', padding = 'same', input_shape = (28, 28, 1)),\n",
    "    layers.Conv2D(64, (5, 5), activation = 'relu', padding = 'same'),\n",
    "    layers.MaxPool2D(2),\n",
    "    \n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "    layers.MaxPool2D(2),\n",
    "    \n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(256, activation = 'relu'),\n",
    "    \n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(9, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# Defining optimizer, loss, and metrics\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(\n",
    "    monitor = 'val_accuracy',\n",
    "    min_delta = 1e-4,\n",
    "    patience = 5,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "# Adding a learning rate annealer\n",
    "reduceLR = ReduceLROnPlateau(\n",
    "    monitor = 'val_accuracy',\n",
    "    patience = 3,\n",
    "    factor = 0.5,\n",
    "    min_lr = 1e-5\n",
    ")\n",
    "# Training model\n",
    "history = model.fit(\n",
    "    trainGen,\n",
    "    validation_data = validGen,\n",
    "    epochs = 20,\n",
    "    callbacks = [earlyStopping, reduceLR],\n",
    "    workers = 4,\n",
    "    use_multiprocessing = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAcc = model.evaluate(testGen)[1] * 100\n",
    "print(f'Testing accuracy of model : {testAcc:.2f}%')\n",
    "model.save('ASLModelV2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=load_model('ASLModelV2.h5')\n",
    "testAcc = Model.evaluate(testGen)[1] \n",
    "print(f'Testing accuracy of model : {testAcc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
